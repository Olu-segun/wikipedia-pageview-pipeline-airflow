## Project Description

This project implements an Apache Airflow DAG to automate the extraction and analysis of Wikipedia pageview data. Specifically, it tracks hourly pageview trends for the "Big Five" tech companies: Amazon, Apple, Facebook, Google, and Microsoft.

---
## Tech Stack

â€¢ Orchestrator: Apache Airflow (DAGs)

â€¢ Database: PostgreSQL

â€¢ Language: Python 3.11
 
---
 ## Project Workflow
 
1.	Extract: Download and unzip Wikipedia pageview data for a specific hour in December 2025.

2.	Transform: Filter the dataset to isolate the five targeted companies and extract pageview counts.

3.	Load: Insert the processed data into a PostgreSQL database.

4.	Analyze: Execute a SQL query to identify the company with the highest engagement.
--
### ğŸ“ Repository Structure
<pre>
Wikipedia-Pageview-Data-Pipeline/
â”‚
â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ wikipedia_company_views_etl_pipeline.py   # main DAG definition
â”‚   â”‚   â”œâ”€â”€ extract_views.py                          # extraction logic
â”‚   â”‚   â”œâ”€â”€ transform_views.py                        # transformation logic
â”‚   â”‚   â”œâ”€â”€ load_views.py                             # loading logic
â”‚   â”‚   â””â”€â”€                           
â”œâ”€â”€ pyenv/
â”œâ”€â”€ logs
â”œâ”€â”€ config
â”œâ”€â”€ docker-compose.yaml                                    # virtual environment
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
</pre>